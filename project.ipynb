{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Marvel dataset\n",
    "marvel_url = \"https://raw.githubusercontent.com/fivethirtyeight/data/master/comic-characters/marvel-wikia-data.csv\"\n",
    "marvel_data = pd.read_csv(marvel_url)\n",
    "\n",
    "# Load the DC dataset\n",
    "dc_url = \"https://raw.githubusercontent.com/fivethirtyeight/data/master/comic-characters/dc-wikia-data.csv\"\n",
    "dc_data = pd.read_csv(dc_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_first_appearance(row):\n",
    "    if pd.isna(row):  # Handle NaN cases\n",
    "        return row\n",
    "    if type(row) == float: # Row has already been converted\n",
    "        return row\n",
    "    row = str(row)\n",
    "    try:\n",
    "        month_map = {\n",
    "                        'January': 1, 'February': 2, 'March': 3, 'April': 4,\n",
    "                        'May': 5, 'June': 6, 'July': 7, 'August': 8,\n",
    "                        'September': 9, 'October': 10, 'November': 11, 'December': 12,\n",
    "                        'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4,\n",
    "                        'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8,\n",
    "                        'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12,\n",
    "                        'Holiday': 11.5\n",
    "                    }\n",
    "        if \"-\" in row:  # Marvel date format (e.g., 'Sep-75')\n",
    "            parts = row.split(\"-\")\n",
    "            year = int(\"19\" + parts[1] if int(parts[1]) > 30 else \"20\" + parts[1])\n",
    "            month_abbrev = parts[0]\n",
    "            month = month_map.get(month_abbrev)\n",
    "        else:  # DC date format (e.g., '1999, April')\n",
    "            parts = row.split(\", \")\n",
    "            if len(parts) == 1:\n",
    "                year = int(parts[0])\n",
    "                month = 1\n",
    "            else:\n",
    "                year = int(parts[0])\n",
    "                month_abbrev = parts[1]\n",
    "                month = month_map.get(month_abbrev)\n",
    "\n",
    "        return year + (month - 1) / 12  # Normalize month to a fraction of a year\n",
    "    except:\n",
    "        print(\"Error parsing date: \" + row)\n",
    "        raise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_data[\"FIRST APPEARANCE\"] = marvel_data[\"FIRST APPEARANCE\"].apply(convert_first_appearance)\n",
    "dc_data[\"FIRST APPEARANCE\"] = dc_data[\"FIRST APPEARANCE\"].apply(convert_first_appearance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_data.rename(columns={\"Year\": \"YEAR\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "combined_data = pd.concat([marvel_data, dc_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_names = marvel_data[\"name\"]\n",
    "dc_names = dc_data[\"name\"]\n",
    "combined_names = combined_data[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_data = marvel_data.drop([\"urlslug\", \"page_id\", \"name\", \"YEAR\"], axis=1)\n",
    "dc_data = dc_data.drop([\"urlslug\", \"page_id\", \"name\", \"YEAR\"], axis=1)\n",
    "combined_data = combined_data.drop([\"urlslug\", \"page_id\", \"name\", \"YEAR\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_dfs = []\n",
    "for column in marvel_data.columns:\n",
    "    marvel_dfs.append((column, pd.DataFrame(marvel_data[column].value_counts(dropna=False), columns=[f\"count\"], index=marvel_data[column].unique())))\n",
    "for column, df in marvel_dfs:\n",
    "    print(f\"Column: {column}\", df, sep=\"\\n\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_dfs = []\n",
    "for column in dc_data.columns:\n",
    "    dc_dfs.append((column, pd.DataFrame(dc_data[column].value_counts(dropna=False), columns=[f\"count\"], index=dc_data[column].unique())))\n",
    "for column, df in dc_dfs:\n",
    "    print(f\"Column: {column}\", df, sep=\"\\n\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dfs = []\n",
    "for column in combined_data.columns:\n",
    "    combined_dfs.append((column, pd.DataFrame(combined_data[column].value_counts(dropna=False), columns=[f\"count\"], index=combined_data[column].unique())))\n",
    "for column, df in combined_dfs:\n",
    "    print(f\"Column: {column}\", df, sep=\"\\n\", end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of target features (exclude \"url\", \"page_id\", and \"name\")\n",
    "target_features = [\"ALIGN\", \"SEX\", \"EYE\", \"HAIR\", \"GSM\", \"ALIVE\", \"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_models_marvel = []\n",
    "rf_models_dc = []\n",
    "rf_models_combined = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_feature in target_features:\n",
    "    #print(f\"\"\"Target feature: {target_feature}\"\"\")\n",
    "\n",
    "    # Create dataset with target_feature as the target column for each category\n",
    "    data_marvel = marvel_data.dropna(subset=[target_feature])\n",
    "    data_dc = dc_data.dropna(subset=[target_feature])\n",
    "    data_combined = combined_data.dropna(subset=[target_feature])\n",
    "\n",
    "    features_marvel = data_marvel.drop(target_feature, axis=1)\n",
    "    features_dc = data_dc.drop(target_feature, axis=1)\n",
    "    features_combined = data_combined.drop(target_feature, axis=1)\n",
    "\n",
    "    targets_marvel = data_marvel[target_feature]\n",
    "    targets_dc = data_dc[target_feature]\n",
    "    targets_combined = data_combined[target_feature]\n",
    "\n",
    "    classes = targets_marvel.unique()\n",
    "    \n",
    "    # Encode target feature\n",
    "    le_marvel = LabelEncoder()\n",
    "    le_dc = LabelEncoder()\n",
    "    le_combined = LabelEncoder()\n",
    "    y_marvel = le_marvel.fit_transform(targets_marvel)\n",
    "    y_dc = le_dc.fit_transform(targets_dc)\n",
    "    y_combined = le_combined.fit_transform(targets_combined)\n",
    "\n",
    "    # One-hot encode features\n",
    "    columns = [tf for tf in target_features if tf != target_feature]\n",
    "    onehot_features_marvel = pd.get_dummies(features_marvel, columns=columns)\n",
    "    onehot_features_dc = pd.get_dummies(features_dc, columns=columns)\n",
    "    onehot_features_combined = pd.get_dummies(features_combined, columns=columns)\n",
    "\n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    imputed_onehot_features_marvel = imputer.fit_transform(onehot_features_marvel)\n",
    "    imputed_onehot_features_dc = imputer.fit_transform(onehot_features_dc)\n",
    "    imputed_onehot_features_combined = imputer.fit_transform(onehot_features_combined)\n",
    "\n",
    "    # Final features dataframe\n",
    "    X_marvel = pd.DataFrame(imputed_onehot_features_marvel, columns=onehot_features_marvel.columns)\n",
    "    X_dc = pd.DataFrame(imputed_onehot_features_dc, columns=onehot_features_dc.columns)\n",
    "    X_combined = pd.DataFrame(imputed_onehot_features_combined, columns=onehot_features_combined.columns)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "\n",
    "    X_train_marvel, X_test_marvel, y_train_marvel, y_test_marvel = train_test_split(X_marvel, y_marvel, test_size=0.2, random_state=42)\n",
    "    X_train_dc, X_test_dc, y_train_dc, y_test_dc = train_test_split(X_dc, y_dc, test_size=0.2, random_state=42)\n",
    "    X_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create RandomForest classifiers for each category\n",
    "    rf_classifier_marvel = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier_dc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier_combined = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Get the unique class labels from the original target data\n",
    "    marvel_unique_class_labels = np.unique(y_marvel)\n",
    "    print(marvel_unique_class_labels)\n",
    "    dc_unique_class_labels = np.unique(y_dc)\n",
    "    combined_unique_class_labels = np.unique(y_combined)\n",
    "\n",
    "    # Convert the unique class labels to a list\n",
    "    marvel_class_names = le_marvel.inverse_transform(marvel_unique_class_labels)\n",
    "    print(marvel_class_names)\n",
    "    dc_class_names = le_dc.inverse_transform(dc_unique_class_labels)\n",
    "    combined_class_names = le_combined.inverse_transform(combined_unique_class_labels)\n",
    "    \n",
    "    # Store the trained models in the respective lists\n",
    "    rf_models_marvel.append((rf_classifier_marvel, X_train_marvel, y_train_marvel, X_test_marvel, y_test_marvel, target_feature, marvel_class_names))\n",
    "    rf_models_dc.append((rf_classifier_dc, X_train_dc, y_train_dc, X_test_dc, y_test_dc, target_feature, dc_class_names))\n",
    "    rf_models_combined.append((rf_classifier_combined, X_train_combined, y_train_combined, X_test_combined, y_test_combined, target_feature, combined_class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rf_model, X_train, y_train, X_test, y_test, target_feature, _ in rf_models_marvel:\n",
    "    try:\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        print(f\"\"\"Accuracy score for Marvel {target_feature} predictions: {accuracy_score(y_test, y_pred)}\"\"\")\n",
    "    except:\n",
    "        print(f\"\"\"Not enough data for Marvel {target_feature} predictions\"\"\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rf_model, X_train, y_train, X_test, y_test, target_feature, _ in rf_models_dc:\n",
    "    try:\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        print(f\"\"\"Accuracy score for DC {target_feature} predictions: {accuracy_score(y_test, y_pred)}\"\"\")\n",
    "    except:\n",
    "        print(f\"\"\"Not enough data for DC {target_feature} predictions\"\"\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rf_model, X_train, y_train, X_test, y_test, target_feature, _ in rf_models_combined:\n",
    "    try:\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        print(f\"\"\"Accuracy score for combined {target_feature} predictions: {accuracy_score(y_test, y_pred)}\"\"\")\n",
    "    except:\n",
    "        print(f\"\"\"Not enough data for combined {target_feature} predictions\"\"\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_models_marvel = []\n",
    "\n",
    "for rf_model, X_train, y_train, X_test, y_test, target_feature, class_names in rf_models_marvel:\n",
    "    print(f\"\"\"Creating SHAP values for Marvel {target_feature} predictions with {len(X_test)} samples\"\"\")\n",
    "    subset_size = min((int(len(X_test) * 0.1) if len(X_test) > 250 else len(X_test)), 10)\n",
    "    print(f\"\"\"Subset size: {subset_size}\"\"\")\n",
    "\n",
    "    explainer = shap.TreeExplainer(rf_model)\n",
    "    shap_values = explainer.shap_values(X_test[:subset_size])\n",
    "    shap_models_marvel.append((explainer, shap_values, X_test[:subset_size], target_feature, class_names))\n",
    "    print(f\"\"\"SHAP values for Marvel {target_feature} predictions created\"\"\")\n",
    "\n",
    "print(\"Marvel SHAP values created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SHAP values for DC\n",
    "\n",
    "shap_models_dc = []\n",
    "\n",
    "for rf_model, X_train, y_train, X_test, y_test, target_feature, class_names in rf_models_dc:\n",
    "    print(f\"\"\"Creating SHAP values for DC {target_feature} predictions with {len(X_test)} samples\"\"\")\n",
    "    subset_size = min((int(len(X_test) * 0.1) if len(X_test) > 250 else len(X_test)), 10)\n",
    "    print(f\"\"\"Subset size: {subset_size}\"\"\")\n",
    "\n",
    "    explainer = shap.TreeExplainer(rf_model)\n",
    "    shap_values = explainer.shap_values(X_test[:subset_size])\n",
    "    shap_models_dc.append((explainer, shap_values, X_test[:subset_size], target_feature, class_names))\n",
    "    print(f\"\"\"SHAP values for DC {target_feature} predictions created\"\"\")\n",
    "\n",
    "print(\"DC SHAP values created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SHAP values for combined\n",
    "\n",
    "shap_models_combined = []\n",
    "\n",
    "for rf_model, X_train, y_train, X_test, y_test, target_feature, class_names in rf_models_combined:\n",
    "    print(f\"\"\"Creating SHAP values for combined {target_feature} predictions with {len(X_test)} samples\"\"\")\n",
    "    subset_size = min((int(len(X_test) * 0.1) if len(X_test) > 250 else len(X_test)), 10)\n",
    "    print(f\"\"\"Subset size: {subset_size}\"\"\")\n",
    "\n",
    "    explainer = shap.TreeExplainer(rf_model)\n",
    "    shap_values = explainer.shap_values(X_test[:subset_size])\n",
    "    shap_models_combined.append((explainer, shap_values, X_test[:subset_size], target_feature, class_names))\n",
    "    print(f\"\"\"SHAP values for combined {target_feature} predictions created\"\"\")\n",
    "\n",
    "print(\"Combined SHAP values created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for Marvel\n",
    "\n",
    "for explainer, shap_values, feature_subset, target_feature, class_names in shap_models_marvel:\n",
    "    num_samples = len(feature_subset)\n",
    "    sample_index = random.randint(0, num_samples - 1)  # Generate a random index within the valid range\n",
    "\n",
    "    print(f\"Creating Summary plot for Marvel {target_feature} predictions\")\n",
    "    shap.summary_plot(shap_values, feature_subset, feature_names=feature_subset.columns, show=False, class_names=class_names)\n",
    "    plt.savefig(f\"figs/summary/Marvel_{target_feature}_summary.png\")\n",
    "    plt.show()\n",
    "    print(f\"Created Summary plot for Marvel {target_feature} predictions\")\n",
    "\n",
    "    print(f\"Creating Waterfall plot for Marvel {target_feature} predictions\")\n",
    "    shap.plots.waterfall(shap.Explanation(values=shap_values[0][sample_index], base_values=explainer.expected_value[0], data=feature_subset.iloc[sample_index]), max_display=10, show=False)\n",
    "    plt.savefig(f\"figs/waterfall/Marvel_{target_feature}_{sample_index}_waterfall.png\")\n",
    "    plt.show()\n",
    "    print(f\"Created Waterfall plot for Marvel {target_feature} predictions\")\n",
    "\n",
    "\n",
    "print(\"Marvel plots created\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for DC\n",
    "\n",
    "for explainer, shap_values, feature_subset, target_feature, class_names in shap_models_dc:\n",
    "    sample_index = random.randint(0, len(feature_subset))\n",
    "\n",
    "    print(f\"\"\"Creating Summary plot for DC {target_feature} predictions\"\"\")\n",
    "    shap.summary_plot(shap_values, feature_subset, feature_names=feature_subset.columns, show=False, class_names=class_names)\n",
    "    plt.savefig(f\"\"\"figs/summary/DC_{target_feature}_summary.png\"\"\")\n",
    "    plt.show()\n",
    "    print(f\"\"\"Created Summary plot for DC {target_feature} predictions\"\"\")\n",
    "\n",
    "    print(f\"Creating Waterfall plot for DC {target_feature} predictions\")\n",
    "    shap.plots.waterfall(shap.Explanation(values=shap_values[0][sample_index], base_values=explainer.expected_value[0], data=feature_subset.iloc[sample_index]), max_display=10, show=False)\n",
    "    plt.savefig(f\"figs/waterfall/DC_{target_feature}_{sample_index}_waterfall.png\")\n",
    "    plt.show()\n",
    "    print(f\"Created Waterfall plot for DC {target_feature} predictions\")\n",
    "\n",
    "\n",
    "print(\"DC plots created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for Combined\n",
    "\n",
    "for explainer, shap_values, feature_subset, target_feature, class_names in shap_models_combined:\n",
    "    sample_index = random.randint(0, len(feature_subset))\n",
    "\n",
    "    print(f\"\"\"Creating Summary plot for Combined {target_feature} predictions\"\"\")\n",
    "    shap.summary_plot(shap_values, feature_subset, feature_names=feature_subset.columns, show=False, class_names=class_names)\n",
    "    plt.savefig(f\"\"\"figs/summary/Combined_{target_feature}_summary.png\"\"\")\n",
    "    plt.show()\n",
    "    print(f\"\"\"Created Summary plot for Combined {target_feature} predictions\"\"\")\n",
    "\n",
    "    print(f\"Creating Waterfall plot for Combined {target_feature} predictions\")\n",
    "    shap.plots.waterfall(shap.Explanation(values=shap_values[0][sample_index], base_values=explainer.expected_value[0], data=feature_subset.iloc[sample_index]), max_display=10, show=False)\n",
    "    plt.savefig(f\"figs/waterfall/Combined_{target_feature}_{sample_index}_waterfall.png\")\n",
    "    plt.show()\n",
    "    print(f\"Created Waterfall plot for Combined {target_feature} predictions\")\n",
    "\n",
    "print(\"Combined plots created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Loop through each dataset\n",
    "for rf_model, X_train, y_train, X_test, y_test, target_feature, class_names in rf_models_marvel:\n",
    "    # Select a random subset of instances from the test data\n",
    "    num_instances = min((int(len(X_test) * 0.1) if len(X_test) > 250 else len(X_test)), 12)\n",
    "    selected_indices = np.random.choice(len(X_test), num_instances, replace=False)\n",
    "    X_test_subset = X_test.iloc[selected_indices]\n",
    "    y_test_subset = y_test[selected_indices]\n",
    "    \n",
    "    # Get the predicted probabilities for the selected instances in the test data\n",
    "    predicted_probabilities = rf_model.predict_proba(X_test_subset)\n",
    "\n",
    "    # Get the subset of class names corresponding to the number of classes\n",
    "    subset_class_names = class_names[:predicted_probabilities.shape[1]]\n",
    "\n",
    "    # Calculate the number of rows and columns for subplots\n",
    "    num_instances_subset, num_classes = predicted_probabilities.shape\n",
    "    num_columns = min(num_classes, 5)  # Limit the number of columns to avoid too many subplots\n",
    "    num_rows = math.ceil(num_instances_subset / num_columns)\n",
    "\n",
    "    # Create a larger plot with subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 15))\n",
    "    fig.suptitle(f\"Predicted Probabilities for {target_feature}\", fontsize=16)\n",
    "\n",
    "    # Loop through each instance and its corresponding predicted probabilities\n",
    "    for i, (probs, ax) in enumerate(zip(predicted_probabilities, axes.flatten())):\n",
    "        character_name = str(marvel_names[selected_indices[i]])  # Convert to string\n",
    "        actual_class = y_test_subset[i]  # Get the actual class value\n",
    "        \n",
    "        # Plot the predicted probabilities as a bar chart\n",
    "        ax.bar(subset_class_names, probs, label=\"Predicted\", alpha=0.7)\n",
    "        \n",
    "        # Plot the actual class value as a point on top of the predicted probabilities\n",
    "        ax.scatter(actual_class, 1, color=\"red\", label=\"Actual\")\n",
    "        \n",
    "        ax.set_title(character_name)  # Set character name as the title\n",
    "        ax.set_xlabel(\"Class\")\n",
    "        ax.set_ylabel(\"Probability\")\n",
    "        ax.set_xticks(range(len(subset_class_names)))  # Set tick positions\n",
    "        ax.set_xticklabels(subset_class_names, rotation=45)  # Set tick labels\n",
    "        ax.legend()  # Show legend\n",
    "        \n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.savefig(f\"\"\"figs/prob_charts/Marvel_{target_feature}_{selected_indices}_probabilities.png\"\"\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each dataset\n",
    "for rf_model, X_train, y_train, X_test, y_test, target_feature, class_names in rf_models_dc:\n",
    "    # Select a random subset of instances from the test data\n",
    "    num_instances = min((int(len(X_test) * 0.1) if len(X_test) > 250 else len(X_test)), 12)\n",
    "    selected_indices = np.random.choice(len(X_test), num_instances, replace=False)\n",
    "    X_test_subset = X_test.iloc[selected_indices]\n",
    "    y_test_subset = y_test[selected_indices]\n",
    "    \n",
    "    # Get the predicted probabilities for the selected instances in the test data\n",
    "    predicted_probabilities = rf_model.predict_proba(X_test_subset)\n",
    "\n",
    "    # Get the subset of class names corresponding to the number of classes\n",
    "    subset_class_names = class_names[:predicted_probabilities.shape[1]]\n",
    "\n",
    "    # Calculate the number of rows and columns for subplots\n",
    "    num_instances_subset, num_classes = predicted_probabilities.shape\n",
    "    num_columns = min(num_classes, 5)  # Limit the number of columns to avoid too many subplots\n",
    "    num_rows = math.ceil(num_instances_subset / num_columns)\n",
    "\n",
    "    # Create a larger plot with subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 15))\n",
    "    fig.suptitle(f\"Predicted Probabilities for {target_feature}\", fontsize=16)\n",
    "\n",
    "    # Loop through each instance and its corresponding predicted probabilities\n",
    "    for i, (probs, ax) in enumerate(zip(predicted_probabilities, axes.flatten())):\n",
    "        character_name = str(dc_names[selected_indices[i]])  # Convert to string\n",
    "        actual_class = y_test_subset[i]  # Get the actual class value\n",
    "        \n",
    "        # Plot the predicted probabilities as a bar chart\n",
    "        ax.bar(subset_class_names, probs, label=\"Predicted\", alpha=0.7)\n",
    "        \n",
    "        # Plot the actual class value as a point on top of the predicted probabilities\n",
    "        ax.scatter(actual_class, 1, color=\"red\", label=\"Actual\")\n",
    "        \n",
    "        ax.set_title(character_name)  # Set character name as the title\n",
    "        ax.set_xlabel(\"Class\")\n",
    "        ax.set_ylabel(\"Probability\")\n",
    "        ax.set_xticks(range(len(subset_class_names)))  # Set tick positions\n",
    "        ax.set_xticklabels(subset_class_names, rotation=45)  # Set tick labels\n",
    "        ax.legend()  # Show legend\n",
    "        \n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.savefig(f\"\"\"figs/prob_charts/DC_{target_feature}_{selected_indices}_probabilities.png\"\"\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each dataset\n",
    "for rf_model, X_train, y_train, X_test, y_test, target_feature, class_names in rf_models_combined:\n",
    "    # Select a random subset of instances from the test data\n",
    "    num_instances = min((int(len(X_test) * 0.1) if len(X_test) > 250 else len(X_test)), 12)\n",
    "    selected_indices = np.random.choice(len(X_test), num_instances, replace=False)\n",
    "    X_test_subset = X_test.iloc[selected_indices]\n",
    "    y_test_subset = y_test[selected_indices]\n",
    "    \n",
    "    # Get the predicted probabilities for the selected instances in the test data\n",
    "    predicted_probabilities = rf_model.predict_proba(X_test_subset)\n",
    "\n",
    "    # Get the subset of class names corresponding to the number of classes\n",
    "    subset_class_names = class_names[:predicted_probabilities.shape[1]]\n",
    "\n",
    "    # Calculate the number of rows and columns for subplots\n",
    "    num_instances_subset, num_classes = predicted_probabilities.shape\n",
    "    num_columns = min(num_classes, 5)  # Limit the number of columns to avoid too many subplots\n",
    "    num_rows = math.ceil(num_instances_subset / num_columns)\n",
    "\n",
    "    # Create a larger plot with subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 15))\n",
    "    fig.suptitle(f\"Predicted Probabilities for {target_feature}\", fontsize=16)\n",
    "\n",
    "    # Loop through each instance and its corresponding predicted probabilities\n",
    "    for i, (probs, ax) in enumerate(zip(predicted_probabilities, axes.flatten())):\n",
    "        character_name = str(combined_names[selected_indices[i]])  # Convert to string\n",
    "        actual_class = y_test_subset[i]  # Get the actual class value\n",
    "        \n",
    "        # Plot the predicted probabilities as a bar chart\n",
    "        ax.bar(subset_class_names, probs, label=\"Predicted\", alpha=0.7)\n",
    "        \n",
    "        # Plot the actual class value as a point on top of the predicted probabilities\n",
    "        ax.scatter(actual_class, 1, color=\"red\", label=\"Actual\")\n",
    "        \n",
    "        ax.set_title(character_name)  # Set character name as the title\n",
    "        ax.set_xlabel(\"Class\")\n",
    "        ax.set_ylabel(\"Probability\")\n",
    "        ax.set_xticks(range(len(subset_class_names)))  # Set tick positions\n",
    "        ax.set_xticklabels(subset_class_names, rotation=45)  # Set tick labels\n",
    "        ax.legend()  # Show legend\n",
    "        \n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.savefig(f\"\"\"figs/prob_charts/Combined_{target_feature}_{selected_indices}_probabilities.png\"\"\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearningDataMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
